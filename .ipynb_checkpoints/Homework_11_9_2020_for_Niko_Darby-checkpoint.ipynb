{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment 7 for Niko Darby \n",
    "\n",
    "- A .zip containing .txt and .docx files is attached.\n",
    "\n",
    "- For each file, remove punctuation and stop words\n",
    "\n",
    "- Produce a single .dat file containing the name of the file in quotes, a colon, then a list of words separated by commas. The list of words per file should be unique. Do not include URLs or phone numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import docx\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, import, and clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = zf.ZipFile('week_8_documents.zip ')\n",
    "file.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Quick refresher procured from the following source: https://www.w3schools.com/python/python_file_open.asp\n",
    "\n",
    "text_file = open(\"week_8_document2.txt\", \"r\")\n",
    "textv = text_file.read()\n",
    "textv = textv.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Week 8 Document 2:',\n",
       " ['Dr',\n",
       "  'Yawn',\n",
       "  'Earl',\n",
       "  'Vickers',\n",
       "  'Boring',\n",
       "  'Bedtime',\n",
       "  'Stories',\n",
       "  'Anthology',\n",
       "  'Insomniacs',\n",
       "  'started',\n",
       "  'harmlessly',\n",
       "  'enough',\n",
       "  'highschool',\n",
       "  'science',\n",
       "  'fair',\n",
       "  'project',\n",
       "  'Yawns',\n",
       "  'Contagious',\n",
       "  'one',\n",
       "  'thing',\n",
       "  'led',\n",
       "  'another',\n",
       "  'was',\n",
       "  'world’s',\n",
       "  'foremost',\n",
       "  'expert',\n",
       "  'subject',\n",
       "  'cared',\n",
       "  'about',\n",
       "  'topic',\n",
       "  'equally',\n",
       "  'suicidal',\n",
       "  'career',\n",
       "  'conferences',\n",
       "  'cocktail',\n",
       "  'parties',\n",
       "  'reasons',\n",
       "  'fully',\n",
       "  'understand',\n",
       "  'discussion',\n",
       "  'yawning',\n",
       "  'considered',\n",
       "  'almost',\n",
       "  'rude',\n",
       "  'boring',\n",
       "  'act',\n",
       "  'itself',\n",
       "  'mere',\n",
       "  'mention',\n",
       "  'research',\n",
       "  'would',\n",
       "  'inevitably',\n",
       "  'bring',\n",
       "  'minor',\n",
       "  'epidemic',\n",
       "  'uncontrollable',\n",
       "  'yawns',\n",
       "  'whether',\n",
       "  'behind',\n",
       "  'back',\n",
       "  'disguised',\n",
       "  'hand',\n",
       "  'right',\n",
       "  'face',\n",
       "  'way',\n",
       "  'ruined',\n",
       "  'countless',\n",
       "  'conventions',\n",
       "  'meetings',\n",
       "  'concerts',\n",
       "  'bachelor',\n",
       "  'wedding',\n",
       "  'receptions',\n",
       "  'number',\n",
       "  'invitations',\n",
       "  'social',\n",
       "  'professional',\n",
       "  'dwindled',\n",
       "  'nothing',\n",
       "  'doubly',\n",
       "  'unfortunate',\n",
       "  'lasted',\n",
       "  'encounters',\n",
       "  'served',\n",
       "  'laboratories',\n",
       "  'additional',\n",
       "  'field',\n",
       "  'conclusion',\n",
       "  'illfated',\n",
       "  'encounter',\n",
       "  'quietly',\n",
       "  'retire',\n",
       "  'corner',\n",
       "  'room',\n",
       "  'take',\n",
       "  'meticulous',\n",
       "  'notes',\n",
       "  'Sometimes',\n",
       "  'surreptitiously',\n",
       "  'time',\n",
       "  'discussions',\n",
       "  'stopwatch',\n",
       "  'carefully',\n",
       "  'noting',\n",
       "  'length',\n",
       "  'initial',\n",
       "  'gestation',\n",
       "  'period',\n",
       "  'predelay',\n",
       "  'duration',\n",
       "  'long',\n",
       "  'inspiratory',\n",
       "  'phase',\n",
       "  'precise',\n",
       "  'moment',\n",
       "  'acme',\n",
       "  'orgasmic',\n",
       "  'peak',\n",
       "  'yawn',\n",
       "  'short',\n",
       "  'expiration',\n",
       "  'contagion',\n",
       "  'interval',\n",
       "  'rate',\n",
       "  'new',\n",
       "  'bystanders',\n",
       "  'afflicted',\n",
       "  'also',\n",
       "  'gather',\n",
       "  'much',\n",
       "  'data',\n",
       "  'possible',\n",
       "  'regarding',\n",
       "  'people',\n",
       "  'involved',\n",
       "  'effort',\n",
       "  'derive',\n",
       "  'correlations',\n",
       "  'personality',\n",
       "  'type',\n",
       "  'susceptibility',\n",
       "  'Realizing',\n",
       "  'share',\n",
       "  'fascination',\n",
       "  'learning',\n",
       "  'yawning’s',\n",
       "  'paralinguistic',\n",
       "  'value',\n",
       "  'role',\n",
       "  'complex',\n",
       "  'arousal',\n",
       "  'defense',\n",
       "  'reflex',\n",
       "  'origin',\n",
       "  'reticular',\n",
       "  'brainstem',\n",
       "  'theories',\n",
       "  'relation',\n",
       "  'borderline',\n",
       "  'hypoxia',\n",
       "  'tried',\n",
       "  'spice',\n",
       "  'famous',\n",
       "  'quotations',\n",
       "  'Aristotle’s',\n",
       "  'donkey',\n",
       "  'urinates',\n",
       "  'sees',\n",
       "  'hears',\n",
       "  'man',\n",
       "  'seeing',\n",
       "  'someone',\n",
       "  'else',\n",
       "  'even',\n",
       "  'used',\n",
       "  'joke',\n",
       "  'pharmacological',\n",
       "  'connection',\n",
       "  'spontaneous',\n",
       "  'erection',\n",
       "  'death',\n",
       "  'happy',\n",
       "  'see',\n",
       "  'without',\n",
       "  'fail',\n",
       "  'recipient',\n",
       "  'conversations',\n",
       "  'ask',\n",
       "  'excused',\n",
       "  'covering',\n",
       "  'mouth',\n",
       "  'make',\n",
       "  'beeline',\n",
       "  'anywhere',\n",
       "  'Sadly',\n",
       "  'work',\n",
       "  'suffered',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'seemed',\n",
       "  'unable',\n",
       "  'concentrate',\n",
       "  'Often',\n",
       "  'fall',\n",
       "  'asleep',\n",
       "  'middle',\n",
       "  'writing',\n",
       "  'paper',\n",
       "  'Even',\n",
       "  'managed',\n",
       "  'complete',\n",
       "  'article',\n",
       "  'rarely',\n",
       "  'either',\n",
       "  'accepted',\n",
       "  'rejected',\n",
       "  'simply',\n",
       "  'ignored',\n",
       "  'manuscript',\n",
       "  'become',\n",
       "  'unreadable',\n",
       "  'academic',\n",
       "  'world',\n",
       "  'publish',\n",
       "  'perish',\n",
       "  'path',\n",
       "  'Students',\n",
       "  'came',\n",
       "  'office',\n",
       "  'more',\n",
       "  'missed',\n",
       "  'bright',\n",
       "  'inquisitive',\n",
       "  'eyes',\n",
       "  'lighting',\n",
       "  'briefly',\n",
       "  'eventually',\n",
       "  'disappearing',\n",
       "  'heavy',\n",
       "  'lids',\n",
       "  'flame',\n",
       "  'curiosity',\n",
       "  'gradually',\n",
       "  'flickering',\n",
       "  'wind',\n",
       "  'physiologic',\n",
       "  'finally',\n",
       "  'extinguished',\n",
       "  'serotoninergic',\n",
       "  'inhibition',\n",
       "  'neuromuscular',\n",
       "  'spindles',\n",
       "  'adrenocorticotropic',\n",
       "  'hormonerelated',\n",
       "  'peptides',\n",
       "  'hypothalamic',\n",
       "  'dopaminergic',\n",
       "  'mechanisms',\n",
       "  'particularly',\n",
       "  'enjoyed',\n",
       "  'showing',\n",
       "  'students',\n",
       "  'nearly',\n",
       "  'fascinating',\n",
       "  'portrait',\n",
       "  'hung',\n",
       "  'wall',\n",
       "  'painting',\n",
       "  'believed',\n",
       "  'priceless',\n",
       "  'apparently',\n",
       "  'dated',\n",
       "  'Renaissance',\n",
       "  'obtain',\n",
       "  'ignorant',\n",
       "  'owner',\n",
       "  'hundred',\n",
       "  'dollars',\n",
       "  'suspected',\n",
       "  'spoken',\n",
       "  'Leonardo',\n",
       "  'da',\n",
       "  'Vinci',\n",
       "  'artist',\n",
       "  'painted',\n",
       "  'picture',\n",
       "  'made',\n",
       "  'everybody',\n",
       "  'saw',\n",
       "  'repeatedly',\n",
       "  'kept',\n",
       "  'represented',\n",
       "  'yawning.',\n",
       "  'professor',\n",
       "  'hoped',\n",
       "  'impress',\n",
       "  'upon',\n",
       "  'reality',\n",
       "  'immediacy',\n",
       "  'phenomenon',\n",
       "  'trigger',\n",
       "  'avalanche',\n",
       "  'questions',\n",
       "  'often',\n",
       "  'suddenly',\n",
       "  'remember',\n",
       "  'urgent',\n",
       "  'appointment',\n",
       "  'side',\n",
       "  'campus',\n",
       "  'lectures',\n",
       "  'reputation',\n",
       "  'being',\n",
       "  'mesmerizing',\n",
       "  'least',\n",
       "  'somniferous',\n",
       "  'rumored',\n",
       "  'render',\n",
       "  'entire',\n",
       "  'classroom',\n",
       "  'unconscious',\n",
       "  'certainly',\n",
       "  'exaggeration',\n",
       "  'displayed',\n",
       "  'remarkable',\n",
       "  'ingenuity',\n",
       "  'devising',\n",
       "  'ways',\n",
       "  'conceal',\n",
       "  'stifle',\n",
       "  'swallow',\n",
       "  'developed',\n",
       "  'elaborate',\n",
       "  'alarm',\n",
       "  'systems',\n",
       "  'keep',\n",
       "  'awake',\n",
       "  'exams',\n",
       "  'called',\n",
       "  'class',\n",
       "  'Meanwhile',\n",
       "  'insomnia',\n",
       "  'frequently',\n",
       "  'audit',\n",
       "  'classes',\n",
       "  'search',\n",
       "  'cure',\n",
       "  'condition',\n",
       "  'evening',\n",
       "  'sat',\n",
       "  'bed',\n",
       "  'reviewing',\n",
       "  'life',\n",
       "  'recalled',\n",
       "  'satisfaction',\n",
       "  'breakthroughs',\n",
       "  'areas',\n",
       "  'fetal',\n",
       "  'temporary',\n",
       "  'yawnrelated',\n",
       "  'hearing',\n",
       "  'loss',\n",
       "  'hysterical',\n",
       "  'paroxysmal',\n",
       "  'fondly',\n",
       "  'remembered',\n",
       "  'mostly',\n",
       "  'seated',\n",
       "  'ovation',\n",
       "  'received',\n",
       "  'still',\n",
       "  'finished',\n",
       "  'presenting',\n",
       "  'groundbreaking',\n",
       "  'mate',\n",
       "  'selection',\n",
       "  'nontechnical',\n",
       "  'book',\n",
       "  'Joy',\n",
       "  'Yawning',\n",
       "  'monograph',\n",
       "  'Proudly',\n",
       "  'never',\n",
       "  'quite',\n",
       "  'reached',\n",
       "  'broader',\n",
       "  'audiences',\n",
       "  'intended',\n",
       "  'nonetheless',\n",
       "  'proud',\n",
       "  'efforts',\n",
       "  'popularize',\n",
       "  'done',\n",
       "  'could',\n",
       "  'do',\n",
       "  'bad',\n",
       "  'reflected',\n",
       "  'stretching',\n",
       "  'closing',\n",
       "  'Soon',\n",
       "  'perhaps',\n",
       "  'dean',\n",
       "  'mayor',\n",
       "  'President',\n",
       "  'awaken',\n",
       "  'asking',\n",
       "  'help',\n",
       "  'something',\n",
       "  'kidnapping',\n",
       "  'terrorist',\n",
       "  'plot',\n",
       "  'expertise',\n",
       "  'desperately',\n",
       "  'needed',\n",
       "  'megaphone',\n",
       "  'cell',\n",
       "  'phone',\n",
       "  'placed',\n",
       "  'dulcet',\n",
       "  'tones',\n",
       "  'calming',\n",
       "  'relaxing',\n",
       "  'defusing',\n",
       "  'situation',\n",
       "  'everyone',\n",
       "  'drifts',\n",
       "  'sleep',\n",
       "  'soft',\n",
       "  'warm',\n",
       "  'comfortable',\n",
       "  'problems',\n",
       "  'wait',\n",
       "  'day',\n",
       "  'now',\n",
       "  'wake',\n",
       "  'tomorrow',\n",
       "  'thanks',\n",
       "  'grateful',\n",
       "  'nation'],\n",
       " None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Help received from the following sources: \n",
    "#https://www.geeksforgeeks.org/string-capitalize-python/\n",
    "#https://www.programiz.com/python-programming/examples/remove-punctuation\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html\n",
    "#https://www.w3schools.com/python/ref_string_replace.asp\n",
    "#https://stackoverflow.com/questions/47038101/save-data-as-a-dat-file\n",
    "#https://www.pitt.edu/~naraehan/python3/split_join.html\n",
    "#https://www.geeksforgeeks.org/string-punctuation-in-python/\n",
    "\n",
    "def dark_filter():\n",
    "    dex = []\n",
    "    zls = []\n",
    "    belly = \"\"\n",
    "    pirate = \"\"\n",
    "    go = \"\"\n",
    "    turkey= \"\"\n",
    "    astronaut = string.punctuation\n",
    "    the_halt = nltk.corpus.stopwords.words('english')\n",
    "    the_bulwark = nltk.corpus.stopwords.words('english')\n",
    "    ship = [belly + parastalsis for parastalsis in textv if parastalsis not in astronaut]\n",
    "    wrecked = [pirate + sphincter for sphincter in ship if sphincter not in the_bulwark]\n",
    "    wrecked[0] = wrecked[0].strip(\".\")\n",
    "    for z in range(0,567,1):\n",
    "        zls = zls + [wrecked[z]]\n",
    "    soul = [turkey + sauce for sauce in zls if sauce not in astronaut ]\n",
    "    for v in range(0,567):\n",
    "        caliban_vex = soul[v].strip(string.punctuation).replace(\"can’t\", \"\").replace('and or', '').replace('“', \"\").replace(\",\", \"\").replace('—',\"\").replace(\"/\",\" \").replace(\"-\",\"\").replace('–', \"\").replace('”',\"\").replace('?', \"\")\n",
    "        dex = dex + [caliban_vex]\n",
    "        dex = dex[0:566]\n",
    "    zero =  [the_halt[i].capitalize() for i in range(0,179)]\n",
    "    rex = [go + c for c in dex if c not in zero]\n",
    "    vex = pd.unique(rex)\n",
    "    vex[45] = ''\n",
    "    vex = vex.tolist()\n",
    "    vex.remove('')\n",
    "    vex.remove('')\n",
    "    vex.remove('it')\n",
    "    vex.remove('so.')\n",
    "    vex.remove('and')\n",
    "    vex.remove('me')\n",
    "    vex.remove('him')\n",
    "    zorro = pd.DataFrame({\"Week 8 Document 2:\":vex})\n",
    "    return \"Week 8 Document 2:\",vex, zorro.to_csv(\"week_8_document2.dat\") \n",
    "dark_filter() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assistance with DOCX procured from: \n",
    "# https://stackabuse.com/reading-and-writing-ms-word-files-in-python-via-python-docx-module/\n",
    "# https://python-docx.readthedocs.io/en/latest/user/documents.html\n",
    "\n",
    "\n",
    "word_file = docx.Document('week_8_document1.docx')\n",
    "word_graphs = word_file.paragraphs\n",
    "the_text = []\n",
    "for paragraphs in word_graphs:\n",
    "    the_text.append(paragraphs.text)\n",
    "the_text = ''.join(the_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Week 8 Document 1:',\n",
       " array(['Multilingual', 'corpora', 'specially', 'formatted', 'sidebyside',\n",
       "        'comparison', 'called', 'aligned', 'parallel', 'There', 'two',\n",
       "        'main', 'types', 'contain', 'texts', 'languages', 'translation',\n",
       "        'corpus', 'one', 'language', 'translations', 'comparable', 'kind',\n",
       "        'cover', 'content', 'other1', 'exploit', 'text', 'alignment',\n",
       "        'identifying', 'equivalent', 'segments', 'phrases', 'sentences',\n",
       "        'prerequisite', 'analysis', 'Machine', 'algorithms', 'translating',\n",
       "        'often', 'trained', 'using', 'fragments', 'comprising', 'first',\n",
       "        'second', 'elementforelement', 'corpus2In', 'order', 'make',\n",
       "        'useful', 'linguistic', 'research', 'subjected', 'process',\n",
       "        'known', 'annotation', 'example', 'annotating', 'partofspeech',\n",
       "        'tagging', 'POStagging', 'information', 'words', 'part', 'speech',\n",
       "        'verb', 'noun', 'adjective', 'etc', 'added', 'form', 'tags',\n",
       "        'Another', 'indicating', 'lemma', 'base', 'word', 'When',\n",
       "        'working', 'researchers', 'use', 'interlinear', 'glossing', 'used',\n",
       "        'bilingualSome', 'structured', 'levels', 'applied', 'particular',\n",
       "        'number', 'smaller', 'may', 'fully', 'parsed', 'Such', 'usually',\n",
       "        'Treebanks', 'Parsed', 'Corpora', 'difficulty', 'ensuring',\n",
       "        'entire', 'completely', 'consistently', 'annotated', 'means',\n",
       "        'containing', 'around', 'three', 'million', 'Other', 'possible',\n",
       "        'including', 'annotations', 'morphology', 'semantics',\n",
       "        'pragmaticsCorpora', 'knowledge', 'linguistics', 'processing',\n",
       "        'various', 'also', 'subject', 'much', 'work', 'computational',\n",
       "        'recognition', 'machine', 'create', 'hidden', 'Markov', 'models',\n",
       "        'purposes', 'frequency', 'lists', 'derived', 'teaching',\n",
       "        'considered', 'type', 'foreign', 'writing', 'aid',\n",
       "        'contextualised', 'grammatical', 'acquired', 'nonnative', 'users',\n",
       "        'exposure', 'authentic', 'allows', 'learners', 'grasp', 'manner',\n",
       "        'sentence', 'formation', 'target', 'enabling', 'effective'],\n",
       "       dtype=object),\n",
       " None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Help received from: \n",
    "#https://www.programiz.com/python-programming/examples/remove-punctuation\n",
    "#https://www.geeksforgeeks.org/string-capitalize-python/\n",
    "#https://www.programiz.com/python-programming/examples/remove-punctuation\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html\n",
    "#https://www.w3schools.com/python/ref_string_replace.asp\n",
    "#https://stackoverflow.com/questions/47038101/save-data-as-a-dat-file\n",
    "#https://www.pitt.edu/~naraehan/python3/split_join.html\n",
    "#https://www.geeksforgeeks.org/string-punctuation-in-python/\n",
    "\n",
    "def absorbingstrike():\n",
    "    ultra_string = \"\"\n",
    "    sausage = \"\"\n",
    "    the_halt = nltk.corpus.stopwords.words('english')\n",
    "    symbols_of_hope = string.punctuation\n",
    "    gland = [ultra_string+power for power in the_text if power not in symbols_of_hope]\n",
    "    vortex = ''.join(gland)\n",
    "    vortex = vortex.split()\n",
    "    links = [sausage + x for x in vortex if x not in the_halt]\n",
    "    links.remove('An')\n",
    "    links.remove('In')\n",
    "    links.remove('In')\n",
    "    links.remove('In')\n",
    "    links.remove('To')\n",
    "    links.remove('The')\n",
    "    links.remove('The')\n",
    "    links = pd.unique(links)\n",
    "    zuchini = pd.DataFrame({\"Week 8 Document 1:\":links})\n",
    "    return \"Week 8 Document 1:\",links, zuchini.to_csv(\"week_8_document1.dat\") \n",
    "absorbingstrike()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
