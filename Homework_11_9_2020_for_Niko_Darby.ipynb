{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment 7 for Niko Darby \n",
    "\n",
    "- A .zip containing .txt and .docx files is attached.\n",
    "\n",
    "- For each file, remove punctuation and stop words\n",
    "\n",
    "- Produce a single .dat file containing the name of the file in quotes, a colon, then a list of words separated by commas. The list of words per file should be unique. Do not include URLs or phone numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import docx\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, import, and clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = zf.ZipFile('week_8_documents.zip ')\n",
    "file.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Quick refresher procured from the following source: https://www.w3schools.com/python/python_file_open.asp\n",
    "\n",
    "text_file = open(\"week_8_document2.txt\", \"r\")\n",
    "textv = text_file.read()\n",
    "textv = textv.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Week 8 Document 2:',\n",
       " ['Dr',\n",
       "  'Yawn',\n",
       "  'Earl',\n",
       "  'Vickers',\n",
       "  'Boring',\n",
       "  'Bedtime',\n",
       "  'Stories',\n",
       "  'Anthology',\n",
       "  'Insomniacs',\n",
       "  'started',\n",
       "  'harmlessly',\n",
       "  'enough',\n",
       "  'highschool',\n",
       "  'science',\n",
       "  'fair',\n",
       "  'project',\n",
       "  'Yawns',\n",
       "  'Contagious',\n",
       "  'one',\n",
       "  'thing',\n",
       "  'led',\n",
       "  'another',\n",
       "  'was',\n",
       "  'world’s',\n",
       "  'foremost',\n",
       "  'expert',\n",
       "  'subject',\n",
       "  'cared',\n",
       "  'about',\n",
       "  'topic',\n",
       "  'equally',\n",
       "  'suicidal',\n",
       "  'career',\n",
       "  'conferences',\n",
       "  'cocktail',\n",
       "  'parties',\n",
       "  'reasons',\n",
       "  'fully',\n",
       "  'understand',\n",
       "  'discussion',\n",
       "  'yawning',\n",
       "  'considered',\n",
       "  'almost',\n",
       "  'rude',\n",
       "  'boring',\n",
       "  'act',\n",
       "  'itself',\n",
       "  'mere',\n",
       "  'mention',\n",
       "  'research',\n",
       "  'would',\n",
       "  'inevitably',\n",
       "  'bring',\n",
       "  'minor',\n",
       "  'epidemic',\n",
       "  'uncontrollable',\n",
       "  'yawns',\n",
       "  'whether',\n",
       "  'behind',\n",
       "  'back',\n",
       "  'disguised',\n",
       "  'hand',\n",
       "  'right',\n",
       "  'face',\n",
       "  'way',\n",
       "  'ruined',\n",
       "  'countless',\n",
       "  'conventions',\n",
       "  'meetings',\n",
       "  'concerts',\n",
       "  'bachelor',\n",
       "  'wedding',\n",
       "  'receptions',\n",
       "  'number',\n",
       "  'invitations',\n",
       "  'social',\n",
       "  'professional',\n",
       "  'dwindled',\n",
       "  'nothing',\n",
       "  'doubly',\n",
       "  'unfortunate',\n",
       "  'lasted',\n",
       "  'encounters',\n",
       "  'served',\n",
       "  'laboratories',\n",
       "  'additional',\n",
       "  'field',\n",
       "  'conclusion',\n",
       "  'illfated',\n",
       "  'encounter',\n",
       "  'quietly',\n",
       "  'retire',\n",
       "  'corner',\n",
       "  'room',\n",
       "  'take',\n",
       "  'meticulous',\n",
       "  'notes',\n",
       "  'Sometimes',\n",
       "  'surreptitiously',\n",
       "  'time',\n",
       "  'discussions',\n",
       "  'stopwatch',\n",
       "  'carefully',\n",
       "  'noting',\n",
       "  'length',\n",
       "  'initial',\n",
       "  'gestation',\n",
       "  'period',\n",
       "  'predelay',\n",
       "  'duration',\n",
       "  'long',\n",
       "  'inspiratory',\n",
       "  'phase',\n",
       "  'precise',\n",
       "  'moment',\n",
       "  'acme',\n",
       "  'orgasmic',\n",
       "  'peak',\n",
       "  'yawn',\n",
       "  'short',\n",
       "  'expiration',\n",
       "  'contagion',\n",
       "  'interval',\n",
       "  'rate',\n",
       "  'new',\n",
       "  'bystanders',\n",
       "  'afflicted',\n",
       "  'also',\n",
       "  'gather',\n",
       "  'much',\n",
       "  'data',\n",
       "  'possible',\n",
       "  'regarding',\n",
       "  'people',\n",
       "  'involved',\n",
       "  'effort',\n",
       "  'derive',\n",
       "  'correlations',\n",
       "  'personality',\n",
       "  'type',\n",
       "  'susceptibility',\n",
       "  'Realizing',\n",
       "  'share',\n",
       "  'fascination',\n",
       "  'learning',\n",
       "  'yawning’s',\n",
       "  'paralinguistic',\n",
       "  'value',\n",
       "  'role',\n",
       "  'complex',\n",
       "  'arousal',\n",
       "  'defense',\n",
       "  'reflex',\n",
       "  'origin',\n",
       "  'reticular',\n",
       "  'brainstem',\n",
       "  'theories',\n",
       "  'relation',\n",
       "  'borderline',\n",
       "  'hypoxia',\n",
       "  'tried',\n",
       "  'spice',\n",
       "  'famous',\n",
       "  'quotations',\n",
       "  'Aristotle’s',\n",
       "  'donkey',\n",
       "  'urinates',\n",
       "  'sees',\n",
       "  'hears',\n",
       "  'man',\n",
       "  'seeing',\n",
       "  'someone',\n",
       "  'else',\n",
       "  'even',\n",
       "  'used',\n",
       "  'joke',\n",
       "  'pharmacological',\n",
       "  'connection',\n",
       "  'spontaneous',\n",
       "  'erection',\n",
       "  'death',\n",
       "  'happy',\n",
       "  'see',\n",
       "  'without',\n",
       "  'fail',\n",
       "  'recipient',\n",
       "  'conversations',\n",
       "  'ask',\n",
       "  'excused',\n",
       "  'covering',\n",
       "  'mouth',\n",
       "  'make',\n",
       "  'beeline',\n",
       "  'anywhere',\n",
       "  'Sadly',\n",
       "  'work',\n",
       "  'suffered',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'seemed',\n",
       "  'unable',\n",
       "  'concentrate',\n",
       "  'Often',\n",
       "  'fall',\n",
       "  'asleep',\n",
       "  'middle',\n",
       "  'writing',\n",
       "  'paper',\n",
       "  'Even',\n",
       "  'managed',\n",
       "  'complete',\n",
       "  'article',\n",
       "  'rarely',\n",
       "  'either',\n",
       "  'accepted',\n",
       "  'rejected',\n",
       "  'simply',\n",
       "  'ignored',\n",
       "  'manuscript',\n",
       "  'become',\n",
       "  'unreadable',\n",
       "  'academic',\n",
       "  'world',\n",
       "  'publish',\n",
       "  'perish',\n",
       "  'path',\n",
       "  'Students',\n",
       "  'came',\n",
       "  'office',\n",
       "  'more',\n",
       "  'missed',\n",
       "  'bright',\n",
       "  'inquisitive',\n",
       "  'eyes',\n",
       "  'lighting',\n",
       "  'briefly',\n",
       "  'eventually',\n",
       "  'disappearing',\n",
       "  'heavy',\n",
       "  'lids',\n",
       "  'flame',\n",
       "  'curiosity',\n",
       "  'gradually',\n",
       "  'flickering',\n",
       "  'wind',\n",
       "  'physiologic',\n",
       "  'finally',\n",
       "  'extinguished',\n",
       "  'serotoninergic',\n",
       "  'inhibition',\n",
       "  'neuromuscular',\n",
       "  'spindles',\n",
       "  'adrenocorticotropic',\n",
       "  'hormonerelated',\n",
       "  'peptides',\n",
       "  'hypothalamic',\n",
       "  'dopaminergic',\n",
       "  'mechanisms',\n",
       "  'particularly',\n",
       "  'enjoyed',\n",
       "  'showing',\n",
       "  'students',\n",
       "  'nearly',\n",
       "  'fascinating',\n",
       "  'portrait',\n",
       "  'hung',\n",
       "  'wall',\n",
       "  'painting',\n",
       "  'believed',\n",
       "  'priceless',\n",
       "  'apparently',\n",
       "  'dated',\n",
       "  'Renaissance',\n",
       "  'obtain',\n",
       "  'ignorant',\n",
       "  'owner',\n",
       "  'hundred',\n",
       "  'dollars',\n",
       "  'suspected',\n",
       "  'spoken',\n",
       "  'Leonardo',\n",
       "  'da',\n",
       "  'Vinci',\n",
       "  'artist',\n",
       "  'painted',\n",
       "  'picture',\n",
       "  'made',\n",
       "  'everybody',\n",
       "  'saw',\n",
       "  'repeatedly',\n",
       "  'kept',\n",
       "  'represented',\n",
       "  'yawning.',\n",
       "  'professor',\n",
       "  'hoped',\n",
       "  'impress',\n",
       "  'upon',\n",
       "  'reality',\n",
       "  'immediacy',\n",
       "  'phenomenon',\n",
       "  'trigger',\n",
       "  'avalanche',\n",
       "  'questions',\n",
       "  'often',\n",
       "  'suddenly',\n",
       "  'remember',\n",
       "  'urgent',\n",
       "  'appointment',\n",
       "  'side',\n",
       "  'campus',\n",
       "  'lectures',\n",
       "  'reputation',\n",
       "  'being',\n",
       "  'mesmerizing',\n",
       "  'least',\n",
       "  'somniferous',\n",
       "  'rumored',\n",
       "  'render',\n",
       "  'entire',\n",
       "  'classroom',\n",
       "  'unconscious',\n",
       "  'certainly',\n",
       "  'exaggeration',\n",
       "  'displayed',\n",
       "  'remarkable',\n",
       "  'ingenuity',\n",
       "  'devising',\n",
       "  'ways',\n",
       "  'conceal',\n",
       "  'stifle',\n",
       "  'swallow',\n",
       "  'developed',\n",
       "  'elaborate',\n",
       "  'alarm',\n",
       "  'systems',\n",
       "  'keep',\n",
       "  'awake',\n",
       "  'exams',\n",
       "  'called',\n",
       "  'class',\n",
       "  'Meanwhile',\n",
       "  'insomnia',\n",
       "  'frequently',\n",
       "  'audit',\n",
       "  'classes',\n",
       "  'search',\n",
       "  'cure',\n",
       "  'condition',\n",
       "  'evening',\n",
       "  'sat',\n",
       "  'bed',\n",
       "  'reviewing',\n",
       "  'life',\n",
       "  'recalled',\n",
       "  'satisfaction',\n",
       "  'breakthroughs',\n",
       "  'areas',\n",
       "  'fetal',\n",
       "  'temporary',\n",
       "  'yawnrelated',\n",
       "  'hearing',\n",
       "  'loss',\n",
       "  'hysterical',\n",
       "  'paroxysmal',\n",
       "  'fondly',\n",
       "  'remembered',\n",
       "  'mostly',\n",
       "  'seated',\n",
       "  'ovation',\n",
       "  'received',\n",
       "  'still',\n",
       "  'finished',\n",
       "  'presenting',\n",
       "  'groundbreaking',\n",
       "  'mate',\n",
       "  'selection',\n",
       "  'nontechnical',\n",
       "  'book',\n",
       "  'Joy',\n",
       "  'Yawning',\n",
       "  'monograph',\n",
       "  'Proudly',\n",
       "  'never',\n",
       "  'quite',\n",
       "  'reached',\n",
       "  'broader',\n",
       "  'audiences',\n",
       "  'intended',\n",
       "  'nonetheless',\n",
       "  'proud',\n",
       "  'efforts',\n",
       "  'popularize',\n",
       "  'done',\n",
       "  'could',\n",
       "  'do',\n",
       "  'bad',\n",
       "  'reflected',\n",
       "  'stretching',\n",
       "  'closing',\n",
       "  'Soon',\n",
       "  'perhaps',\n",
       "  'dean',\n",
       "  'mayor',\n",
       "  'President',\n",
       "  'awaken',\n",
       "  'asking',\n",
       "  'help',\n",
       "  'something',\n",
       "  'kidnapping',\n",
       "  'terrorist',\n",
       "  'plot',\n",
       "  'expertise',\n",
       "  'desperately',\n",
       "  'needed',\n",
       "  'megaphone',\n",
       "  'cell',\n",
       "  'phone',\n",
       "  'placed',\n",
       "  'dulcet',\n",
       "  'tones',\n",
       "  'calming',\n",
       "  'relaxing',\n",
       "  'defusing',\n",
       "  'situation',\n",
       "  'everyone',\n",
       "  'drifts',\n",
       "  'sleep',\n",
       "  'soft',\n",
       "  'warm',\n",
       "  'comfortable',\n",
       "  'problems',\n",
       "  'wait',\n",
       "  'day',\n",
       "  'now',\n",
       "  'wake',\n",
       "  'tomorrow',\n",
       "  'thanks',\n",
       "  'grateful',\n",
       "  'nation'],\n",
       " None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Help received from the following sources: \n",
    "#https://www.geeksforgeeks.org/string-capitalize-python/\n",
    "#https://www.programiz.com/python-programming/examples/remove-punctuation\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html\n",
    "#https://www.w3schools.com/python/ref_string_replace.asp\n",
    "#https://stackoverflow.com/questions/47038101/save-data-as-a-dat-file\n",
    "#https://www.pitt.edu/~naraehan/python3/split_join.html\n",
    "#https://www.geeksforgeeks.org/string-punctuation-in-python/\n",
    "\n",
    "def dark_filter():\n",
    "    dex = []\n",
    "    zls = []\n",
    "    belly = \"\"\n",
    "    pirate = \"\"\n",
    "    go = \"\"\n",
    "    turkey= \"\"\n",
    "    astronaut = string.punctuation\n",
    "    the_halt = nltk.corpus.stopwords.words('english')\n",
    "    the_bulwark = nltk.corpus.stopwords.words('english')\n",
    "    ship = [belly + parastalsis for parastalsis in textv if parastalsis not in astronaut]\n",
    "    wrecked = [pirate + sphincter for sphincter in ship if sphincter not in the_bulwark]\n",
    "    wrecked[0] = wrecked[0].strip(\".\")\n",
    "    for z in range(0,567,1):\n",
    "        zls = zls + [wrecked[z]]\n",
    "    soul = [turkey + sauce for sauce in zls if sauce not in astronaut ]\n",
    "    for v in range(0,567):\n",
    "        caliban_vex = soul[v].strip(string.punctuation).replace(\"can’t\", \"\").replace('and or', '').replace('“', \"\").replace(\",\", \"\").replace('—',\"\").replace(\"/\",\" \").replace(\"-\",\"\").replace('–', \"\").replace('”',\"\").replace('?', \"\")\n",
    "        dex = dex + [caliban_vex]\n",
    "        dex = dex[0:566]\n",
    "    zero =  [the_halt[i].capitalize() for i in range(0,179)]\n",
    "    rex = [go + c for c in dex if c not in zero]\n",
    "    vex = pd.unique(rex)\n",
    "    vex[45] = ''\n",
    "    vex = vex.tolist()\n",
    "    vex.remove('')\n",
    "    vex.remove('')\n",
    "    vex.remove('it')\n",
    "    vex.remove('so.')\n",
    "    vex.remove('and')\n",
    "    vex.remove('me')\n",
    "    vex.remove('him')\n",
    "    vex.remove()\n",
    "    zorro = pd.DataFrame({\"Week 8 Document 2:\":vex})\n",
    "    return \"Week 8 Document 2:\",vex, zorro.to_csv(\"week_8_document2.dat\") \n",
    "dark_filter() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assistance with DOCX procured from: \n",
    "# https://stackabuse.com/reading-and-writing-ms-word-files-in-python-via-python-docx-module/\n",
    "# https://python-docx.readthedocs.io/en/latest/user/documents.html\n",
    "\n",
    "\n",
    "word_file = docx.Document('week_8_document1.docx')\n",
    "word_graphs = word_file.paragraphs\n",
    "the_text = []\n",
    "for paragraphs in word_graphs:\n",
    "    the_text.append(paragraphs.text)\n",
    "the_text = ''.join(the_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Week 8 Document 1:',\n",
       " ['Multilingual',\n",
       "  'corpora',\n",
       "  'specially',\n",
       "  'formatted',\n",
       "  'sidebyside',\n",
       "  'comparison',\n",
       "  'called',\n",
       "  'aligned',\n",
       "  'parallel',\n",
       "  'There',\n",
       "  'two',\n",
       "  'main',\n",
       "  'types',\n",
       "  'contain',\n",
       "  'texts',\n",
       "  'languages',\n",
       "  'translation',\n",
       "  'corpus',\n",
       "  'one',\n",
       "  'language',\n",
       "  'translations',\n",
       "  'comparable',\n",
       "  'kind',\n",
       "  'cover',\n",
       "  'content',\n",
       "  'other1',\n",
       "  'exploit',\n",
       "  'text',\n",
       "  'alignment',\n",
       "  'identifying',\n",
       "  'equivalent',\n",
       "  'segments',\n",
       "  'phrases',\n",
       "  'sentences',\n",
       "  'prerequisite',\n",
       "  'analysis',\n",
       "  'Machine',\n",
       "  'algorithms',\n",
       "  'translating',\n",
       "  'often',\n",
       "  'trained',\n",
       "  'using',\n",
       "  'fragments',\n",
       "  'comprising',\n",
       "  'first',\n",
       "  'second',\n",
       "  'elementforelement',\n",
       "  'corpus2In',\n",
       "  'order',\n",
       "  'make',\n",
       "  'useful',\n",
       "  'linguistic',\n",
       "  'research',\n",
       "  'subjected',\n",
       "  'process',\n",
       "  'known',\n",
       "  'annotation',\n",
       "  'example',\n",
       "  'annotating',\n",
       "  'partofspeech',\n",
       "  'tagging',\n",
       "  'POStagging',\n",
       "  'information',\n",
       "  'words',\n",
       "  'part',\n",
       "  'speech',\n",
       "  'verb',\n",
       "  'noun',\n",
       "  'adjective',\n",
       "  'etc',\n",
       "  'added',\n",
       "  'form',\n",
       "  'tags',\n",
       "  'Another',\n",
       "  'indicating',\n",
       "  'lemma',\n",
       "  'base',\n",
       "  'word',\n",
       "  'When',\n",
       "  'working',\n",
       "  'researchers',\n",
       "  'use',\n",
       "  'interlinear',\n",
       "  'glossing',\n",
       "  'used',\n",
       "  'bilingualSome',\n",
       "  'structured',\n",
       "  'levels',\n",
       "  'applied',\n",
       "  'particular',\n",
       "  'number',\n",
       "  'smaller',\n",
       "  'may',\n",
       "  'fully',\n",
       "  'parsed',\n",
       "  'Such',\n",
       "  'usually',\n",
       "  'Treebanks',\n",
       "  'Parsed',\n",
       "  'Corpora',\n",
       "  'difficulty',\n",
       "  'ensuring',\n",
       "  'entire',\n",
       "  'completely',\n",
       "  'consistently',\n",
       "  'annotated',\n",
       "  'means',\n",
       "  'containing',\n",
       "  'around',\n",
       "  'three',\n",
       "  'million',\n",
       "  'Other',\n",
       "  'possible',\n",
       "  'including',\n",
       "  'annotations',\n",
       "  'morphology',\n",
       "  'semantics',\n",
       "  'pragmaticsCorpora',\n",
       "  'knowledge',\n",
       "  'linguistics',\n",
       "  'processing',\n",
       "  'various',\n",
       "  'also',\n",
       "  'subject',\n",
       "  'much',\n",
       "  'work',\n",
       "  'computational',\n",
       "  'recognition',\n",
       "  'machine',\n",
       "  'create',\n",
       "  'hidden',\n",
       "  'Markov',\n",
       "  'models',\n",
       "  'purposes',\n",
       "  'frequency',\n",
       "  'lists',\n",
       "  'derived',\n",
       "  'teaching',\n",
       "  'considered',\n",
       "  'type',\n",
       "  'foreign',\n",
       "  'writing',\n",
       "  'aid',\n",
       "  'contextualised',\n",
       "  'grammatical',\n",
       "  'acquired',\n",
       "  'nonnative',\n",
       "  'users',\n",
       "  'exposure',\n",
       "  'authentic',\n",
       "  'allows',\n",
       "  'learners',\n",
       "  'grasp',\n",
       "  'manner',\n",
       "  'sentence',\n",
       "  'formation',\n",
       "  'target',\n",
       "  'enabling',\n",
       "  'effective'],\n",
       " None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Help received from: \n",
    "#https://www.programiz.com/python-programming/examples/remove-punctuation\n",
    "#https://www.geeksforgeeks.org/string-capitalize-python/\n",
    "#https://www.programiz.com/python-programming/examples/remove-punctuation\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html\n",
    "#https://www.w3schools.com/python/ref_string_replace.asp\n",
    "#https://stackoverflow.com/questions/47038101/save-data-as-a-dat-file\n",
    "#https://www.pitt.edu/~naraehan/python3/split_join.html\n",
    "#https://www.geeksforgeeks.org/string-punctuation-in-python/\n",
    "\n",
    "def absorbingstrike():\n",
    "    ultra_string = \"\"\n",
    "    sausage = \"\"\n",
    "    the_halt = nltk.corpus.stopwords.words('english')\n",
    "    symbols_of_hope = string.punctuation\n",
    "    gland = [ultra_string+power for power in the_text if power not in symbols_of_hope]\n",
    "    vortex = ''.join(gland)\n",
    "    vortex = vortex.split()\n",
    "    links = [sausage + x for x in vortex if x not in the_halt]\n",
    "    links.remove('An')\n",
    "    links.remove('In')\n",
    "    links.remove('In')\n",
    "    links.remove('In')\n",
    "    links.remove('To')\n",
    "    links.remove('The')\n",
    "    links.remove('The')\n",
    "    links = pd.unique(links)\n",
    "    links = links.tolist()\n",
    "    zuchini = pd.DataFrame({\"Week 8 Document 1:\":links})\n",
    "    return \"Week 8 Document 1:\",links, zuchini.to_csv(\"week_8_document1.dat\") \n",
    "absorbingstrike()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
